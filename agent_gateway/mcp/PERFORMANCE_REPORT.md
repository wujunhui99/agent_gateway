# MCP Python Sandbox 性能测试报告

## 📊 执行摘要

本报告对比了当前实现和优化版本的性能差异。测试结果显示，**优化版本实现了惊人的性能提升**。

### 关键指标

| 指标 | 当前实现 | 优化版本 | 改进幅度 |
|------|----------|----------|----------|
| **平均延迟** | ~245ms | ~0.52ms | **99.8% ↓** |
| **总吞吐量** | 4.05 calls/s | 1901.25 calls/s | **469x ↑** |
| **P95 延迟** | ~347ms | ~0.7ms | **99.8% ↓** |

---

## 🎯 测试环境

- **测试时间**: 2025-10-29
- **Docker 容器**: python:3.11-slim
- **测试总调用数**: 500 次 (250 baseline + 250 optimized)
- **测试类型**: 7 种不同的工作负载

---

## 📈 详细性能对比

### 1. Simple Calculation (简单计算: 1+1)

**用途**: 测试最小开销场景

| 指标 | Baseline | Optimized | 改进 |
|------|----------|-----------|------|
| 平均延迟 | 235.93ms | 0.49ms | **99.79%** |
| 中位数延迟 | 223.21ms | 0.48ms | **99.79%** |
| P95 延迟 | 266.60ms | 0.60ms | **99.78%** |
| 吞吐量 | 4.24/s | 2047.79/s | **48,215%** |

**分析**: 简单计算最能体现固定开销的影响。优化版本消除了 subprocess 和 docker exec 的重复开销。

---

### 2. Loop Calculation (循环计算: sum(range(1000)))

**用途**: 测试 CPU 密集型任务

| 指标 | Baseline | Optimized | 改进 |
|------|----------|-----------|------|
| 平均延迟 | 238.27ms | 0.48ms | **99.80%** |
| 中位数延迟 | 224.41ms | 0.47ms | **99.79%** |
| P95 延迟 | 297.73ms | 0.56ms | **99.81%** |
| 吞吐量 | 4.20/s | 2079.73/s | **49,456%** |

**分析**: 即使是计算密集型任务，优化版本仍然显著领先，说明执行本身的开销极小。

---

### 3. String Operations (字符串操作: 'hello' * 100)

**用途**: 测试字符串处理性能

| 指标 | Baseline | Optimized | 改进 |
|------|----------|-----------|------|
| 平均延迟 | 246.25ms | 0.65ms | **99.74%** |
| 中位数延迟 | 228.20ms | 0.61ms | **99.73%** |
| P95 延迟 | 407.49ms | 1.03ms | **99.75%** |
| 吞吐量 | 4.06/s | 1532.97/s | **37,650%** |

**分析**: 字符串操作稍慢，但仍有 1500+ calls/s 的吞吐量。

---

### 4. List Comprehension (列表推导: [i**2 for i in range(100)])

**用途**: 测试列表和迭代性能

| 指标 | Baseline | Optimized | 改进 |
|------|----------|-----------|------|
| 平均延迟 | 244.17ms | 0.52ms | **99.79%** |
| 中位数延迟 | 221.84ms | 0.50ms | **99.77%** |
| P95 延迟 | 360.14ms | 0.65ms | **99.82%** |
| 吞吐量 | 4.10/s | 1931.39/s | **47,061%** |

---

### 5. Dictionary Operations (字典操作)

**用途**: 测试字典构建和查询性能

| 指标 | Baseline | Optimized | 改进 |
|------|----------|-----------|------|
| 平均延迟 | 274.30ms | 0.53ms | **99.81%** |
| 中位数延迟 | 245.39ms | 0.53ms | **99.78%** |
| P95 延迟 | 474.44ms | 0.67ms | **99.86%** |
| 吞吐量 | 3.65/s | 1873.14/s | **51,282%** |

**分析**: 字典操作在 baseline 中最慢，优化后改进最显著。

---

### 6. JSON Parsing (JSON 解析)

**用途**: 测试 JSON 序列化/反序列化

| 指标 | Baseline | Optimized | 改进 |
|------|----------|-----------|------|
| 平均延迟 | 242.52ms | 0.47ms | **99.81%** |
| 中位数延迟 | 229.90ms | 0.47ms | **99.80%** |
| P95 延迟 | 302.78ms | 0.54ms | **99.82%** |
| 吞吐量 | 4.12/s | 2112.51/s | **51,133%** |

**分析**: 优化版本在 JSON 处理上表现最佳，达到 2112 calls/s。

---

### 7. Mixed Workload (混合负载)

**用途**: 模拟真实使用场景

| 指标 | Baseline | Optimized | 改进 |
|------|----------|-----------|------|
| 平均延迟 | 251.50ms | 0.55ms | **99.78%** |
| 中位数延迟 | 226.23ms | 0.51ms | **99.77%** |
| P95 延迟 | 331.58ms | 0.79ms | **99.76%** |
| P99 延迟 | 984.90ms | 0.93ms | **99.91%** |
| 吞吐量 | 3.98/s | 1829.40/s | **45,911%** |

**分析**: 混合负载最接近实际场景，优化版本仍保持近 2000 calls/s 的吞吐量。

---

## 🔍 性能瓶颈分析

### Baseline 实现的瓶颈 (executor.py:17-64)

```python
# 每次调用都执行以下操作:
subprocess.run([
    "run_tool.sh",           # 1. 启动新的 bash 进程 (~5-20ms)
    "python_exec.py",        # 2. docker compose exec (~20-50ms)
    payload_json             # 3. 启动 Python 解释器 (~50-150ms)
])                           # 4. 执行代码 (~1-10ms)
                             # 5. 返回结果 (~5-10ms)
# 总计: ~80-240ms 固定开销
```

**问题识别:**
- ❌ 每次创建新进程 (fork + exec)
- ❌ 每次 docker exec (Docker API 调用)
- ❌ 每次启动 Python 解释器
- ❌ 多次 JSON 序列化/反序列化

### 优化版本的改进 (executor_optimized.py:16-97)

```python
# 首次调用: 启动持久化进程 (~100-200ms, 仅一次)
_process = subprocess.Popen([...], stdin=PIPE, stdout=PIPE)

# 后续调用: 通过管道通信
_process.stdin.write(request_json + "\n")  # ~0.1ms
result = _process.stdout.readline()        # ~0.3-0.5ms
# 总计: ~0.4-0.6ms 每次调用
```

**改进措施:**
- ✅ 进程复用 (只启动一次)
- ✅ 解释器复用 (无启动开销)
- ✅ 管道通信 (无 docker exec 开销)
- ✅ 线程安全 (使用锁保护)
- ✅ 自动重启 (进程崩溃时自动恢复)

---

## 💡 延迟分布分析

### Baseline 延迟分布
```
Min:     ~205ms  (最快情况)
P50:     ~226ms  (中位数)
P95:     ~347ms  (95% 以下)
P99:     ~605ms  (99% 以下)
Max:     ~985ms  (最慢情况)
```

**特点**: 延迟稳定在 200-300ms，偶尔出现 500ms+ 的长尾

### Optimized 延迟分布
```
Min:     ~0.35ms (最快情况)
P50:     ~0.50ms (中位数)
P95:     ~0.70ms (95% 以下)
P99:     ~0.93ms (99% 以下)
Max:     ~1.06ms (最慢情况)
```

**特点**: 延迟极低且稳定，无长尾现象

---

## 📊 吞吐量对比

### Baseline 吞吐量

```
最高: 4.24 calls/s  (simple_calc)
平均: 4.05 calls/s
最低: 3.65 calls/s  (dict_ops)
```

**限制因素**: 固定开销占主导，代码复杂度影响小

### Optimized 吞吐量

```
最高: 2112 calls/s  (json_parsing)
平均: 1915 calls/s
最低: 1533 calls/s  (string_ops)
```

**限制因素**: 代码执行时间本身，网络/进程开销可忽略

---

## 💰 成本效益分析

### 资源利用率提升

假设一个 agent 每分钟执行 10 次 Python 代码:

**Baseline 实现:**
- 执行时间: 10 × 245ms = 2.45s
- CPU 空闲率: 95.9% (大部分时间在等待进程创建)
- 可服务请求: ~240 requests/min

**Optimized 实现:**
- 执行时间: 10 × 0.5ms = 5ms
- CPU 利用率: 有效利用
- 可服务请求: ~114,000 requests/min

**性能提升**: **475x**

### 服务器成本节省

如果需要支持 1000 并发用户，每个用户每分钟调用 5 次:

**Baseline 实现:**
- 需要服务器数: ~21 台
- 每月成本: ~$2,100 (假设 $100/台/月)

**Optimized 实现:**
- 需要服务器数: 1 台
- 每月成本: ~$100

**成本节省**: **95%**

---

## ⚡ 实际场景影响

### 场景 1: 实时聊天机器人

**Baseline**:
- 响应时间: 245ms (仅代码执行)
- 用户体验: 明显延迟

**Optimized**:
- 响应时间: 0.5ms (代码执行)
- 用户体验: 几乎无感知

### 场景 2: 批量数据处理

处理 1000 条数据，每条需要一次 Python 调用:

**Baseline**:
- 总时间: ~245 秒 (4 分钟)
- 并行度: 受限

**Optimized**:
- 总时间: ~0.5 秒
- 并行度: 可大幅提升

### 场景 3: 高频交易 / 实时决策

每秒需要 100 次计算:

**Baseline**:
- 不可行 (最高 4 calls/s)

**Optimized**:
- 轻松应对 (最高 2000+ calls/s)

---

## 🛡️ 稳定性和可靠性

### 错误处理

**优化版本包含:**
- ✅ 进程崩溃自动重启
- ✅ 线程安全锁保护
- ✅ 超时检测 (可配置)
- ✅ 优雅关闭 (atexit 清理)

### 安全性

两个版本均保持相同的安全隔离:
- ✅ Docker 容器隔离
- ✅ 无网络访问 (network_mode: none)
- ✅ 只读卷挂载
- ⚠️ 建议添加: 内存/CPU 限制

---

## 📋 建议和下一步

### 立即行动

1. **生产环境部署**: 优化版本已准备好用于生产
2. **监控指标**: 添加 Prometheus/Grafana 监控
3. **资源限制**: 在 docker-compose.yml 添加资源限制

### 短期优化 (1-2 周)

1. **预加载库**: 启动时预导入 numpy, pandas
2. **进程池**: 维护多个进程处理并发
3. **结果缓存**: 缓存重复的代码执行结果

### 长期规划 (1-3 月)

1. **WebAssembly**: 考虑使用 WASM 沙箱
2. **分布式执行**: 跨多台服务器负载均衡
3. **JIT 编译**: 使用 PyPy 等 JIT 引擎

---

## 📝 结论

优化版本的性能提升**远超预期**:

✅ **延迟降低 99.8%** (245ms → 0.5ms)
✅ **吞吐量提升 469 倍** (4 → 1900 calls/s)
✅ **成本节省 95%** (服务器需求大幅降低)
✅ **用户体验提升** (响应时间几乎无感知)

**强烈建议立即采用优化版本！**

---

## 附录: 使用优化版本

修改 `tools.py:229`:

```python
# 方式 1: 直接替换导入
from .mcp.executor_optimized import run_python_sandbox_optimized as run_python_sandbox

# 方式 2: 修改函数调用
from .mcp.executor_optimized import run_python_sandbox_optimized, cleanup_executor
import atexit

def _python_execute_sync(code: str, input: Optional[str] = None):
    result = run_python_sandbox_optimized(code, input)
    return {"status": "success", **result}

# 注册清理函数
atexit.register(cleanup_executor)
```

---

**报告生成时间**: 2025-10-29
**测试工具**: benchmark.py
**原始数据**: benchmark_results.json
